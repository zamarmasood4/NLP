{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "s_stemmer = SnowballStemmer(language='english')\n",
    "\n",
    "\n",
    "# Paragraphs:\n",
    "txt1=(\"Although the Braille system gained immediate popularity with the blind students at the Institute in Paris,it had to gain acceptance among the sighted before its adoption throughout France.\")\n",
    "\n",
    "txt2=(\"Pakistan, located in South Asia, is a diverse nation rich in culture, history, and landscapes. Its vibrant cities, such as Karachi and Lahore, contrast with its stunning natural beauty, including the majestic Himalayas and Arabian Sea coastline\")\n",
    "\n",
    "\n",
    "dox_1=nlp(txt1)\n",
    "dox_2=nlp(txt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tknization(dox):\n",
    "    tkns = []\n",
    "    for t in dox:\n",
    "        tkns.append(t.text)\n",
    "    return tkns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StopWords_Removal(dox):\n",
    "    tkns = []\n",
    "    for t in dox:\n",
    "        if not t.is_stop:\n",
    "            tkns.append(t.text)\n",
    "    return tkns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def POS_tag(dox):\n",
    "    pos_tags = []\n",
    "    for t in dox:\n",
    "        pos_tags.append((t.text, t.pos_, t.tag_))\n",
    "    return pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatiz(dox):\n",
    "    lemma = []\n",
    "    for t in dox:\n",
    "        lemma.append((t.lemma_))\n",
    "    return lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Stemming(dox):\n",
    "    for w in dox:\n",
    "      print(w.text+' --> '+s_stemmer.stem(w.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(dox):\n",
    "    print(\"Length of nlp.vocab:\", len(nlp.vocab))\n",
    "    print(\"nlp.vocab:\", nlp.vocab)\n",
    "    print(\"Length of dox.vocab:\", len(dox.vocab))\n",
    "    print(\"dox.vocab:\", dox.vocab)\n",
    "    for tkn in range(100):\n",
    "     print(nlp.vocab[tkn].text, end=\" | \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Although', 'the', 'Braille', 'system', 'gained', 'immediate', 'popularity', 'with', 'the', 'blind', 'students', 'at', 'the', 'Institute', 'in', 'Paris', ',', 'it', 'had', 'to', 'gain', 'acceptance', 'among', 'the', 'sighted', 'before', 'its', 'adoption', 'throughout', 'France', '.']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "['Pakistan', ',', 'located', 'South', 'Asia', ',', 'diverse', 'nation', 'rich', 'culture', ',', 'history', ',', 'landscapes', '.', 'vibrant', 'cities', ',', 'Karachi', 'Lahore', ',', 'contrast', 'stunning', 'natural', 'beauty', ',', 'including', 'majestic', 'Himalayas', 'Arabian', 'Sea', 'coastline']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Length of nlp.vocab: 816\n",
      "nlp.vocab: <spacy.vocab.Vocab object at 0x000001FF59F2DC60>\n",
      "Length of dox.vocab: 816\n",
      "dox.vocab: <spacy.vocab.Vocab object at 0x000001FF59F2DC60>\n",
      " | IS_ALPHA | IS_ASCII | IS_DIGIT | IS_LOWER | IS_PUNCT | IS_SPACE | IS_TITLE | IS_UPPER | LIKE_URL | LIKE_NUM | LIKE_EMAIL | IS_STOP | IS_OOV_DEPRECATED | IS_BRACKET | IS_QUOTE | IS_LEFT_PUNCT | IS_RIGHT_PUNCT | IS_CURRENCY | FLAG19 | FLAG20 | FLAG21 | FLAG22 | FLAG23 | FLAG24 | FLAG25 | FLAG26 | FLAG27 | FLAG28 | FLAG29 | FLAG30 | FLAG31 | FLAG32 | FLAG33 | FLAG34 | FLAG35 | FLAG36 | FLAG37 | FLAG38 | FLAG39 | FLAG40 | FLAG41 | FLAG42 | FLAG43 | FLAG44 | FLAG45 | FLAG46 | FLAG47 | FLAG48 | FLAG49 | FLAG50 | FLAG51 | FLAG52 | FLAG53 | FLAG54 | FLAG55 | FLAG56 | FLAG57 | FLAG58 | FLAG59 | FLAG60 | FLAG61 | FLAG62 | FLAG63 | ID | ORTH | LOWER | NORM | SHAPE | PREFIX | SUFFIX | LENGTH | CLUSTER | LEMMA | POS | TAG | DEP | ENT_IOB | ENT_TYPE | HEAD | SENT_START | SPACY | PROB | LANG | ADJ | ADP | ADV | AUX | CONJ | CCONJ | DET | INTJ | NOUN | NUM | PART | PRON | PROPN | PUNCT | SCONJ | SYM | None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "[('Although', 'SCONJ', 'IN'), ('the', 'DET', 'DT'), ('Braille', 'PROPN', 'NNP'), ('system', 'NOUN', 'NN'), ('gained', 'VERB', 'VBD'), ('immediate', 'ADJ', 'JJ'), ('popularity', 'NOUN', 'NN'), ('with', 'ADP', 'IN'), ('the', 'DET', 'DT'), ('blind', 'ADJ', 'JJ'), ('students', 'NOUN', 'NNS'), ('at', 'ADP', 'IN'), ('the', 'DET', 'DT'), ('Institute', 'PROPN', 'NNP'), ('in', 'ADP', 'IN'), ('Paris', 'PROPN', 'NNP'), (',', 'PUNCT', ','), ('it', 'PRON', 'PRP'), ('had', 'VERB', 'VBD'), ('to', 'PART', 'TO'), ('gain', 'VERB', 'VB'), ('acceptance', 'NOUN', 'NN'), ('among', 'ADP', 'IN'), ('the', 'DET', 'DT'), ('sighted', 'ADJ', 'JJ'), ('before', 'ADP', 'IN'), ('its', 'PRON', 'PRP$'), ('adoption', 'NOUN', 'NN'), ('throughout', 'ADP', 'IN'), ('France', 'PROPN', 'NNP'), ('.', 'PUNCT', '.')]\n",
      "\n",
      "======================================================================\n",
      "\n",
      "['Pakistan', ',', 'locate', 'in', 'South', 'Asia', ',', 'be', 'a', 'diverse', 'nation', 'rich', 'in', 'culture', ',', 'history', ',', 'and', 'landscape', '.', 'its', 'vibrant', 'city', ',', 'such', 'as', 'Karachi', 'and', 'Lahore', ',', 'contrast', 'with', 'its', 'stunning', 'natural', 'beauty', ',', 'include', 'the', 'majestic', 'Himalayas', 'and', 'Arabian', 'Sea', 'coastline']\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Pakistan --> pakistan\n",
      ", --> ,\n",
      "located --> locat\n",
      "in --> in\n",
      "South --> south\n",
      "Asia --> asia\n",
      ", --> ,\n",
      "is --> is\n",
      "a --> a\n",
      "diverse --> divers\n",
      "nation --> nation\n",
      "rich --> rich\n",
      "in --> in\n",
      "culture --> cultur\n",
      ", --> ,\n",
      "history --> histori\n",
      ", --> ,\n",
      "and --> and\n",
      "landscapes --> landscap\n",
      ". --> .\n",
      "Its --> it\n",
      "vibrant --> vibrant\n",
      "cities --> citi\n",
      ", --> ,\n",
      "such --> such\n",
      "as --> as\n",
      "Karachi --> karachi\n",
      "and --> and\n",
      "Lahore --> lahor\n",
      ", --> ,\n",
      "contrast --> contrast\n",
      "with --> with\n",
      "its --> it\n",
      "stunning --> stun\n",
      "natural --> natur\n",
      "beauty --> beauti\n",
      ", --> ,\n",
      "including --> includ\n",
      "the --> the\n",
      "majestic --> majest\n",
      "Himalayas --> himalaya\n",
      "and --> and\n",
      "Arabian --> arabian\n",
      "Sea --> sea\n",
      "coastline --> coastlin\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "tknize_text = tknization(dox_1)\n",
    "print(tknize_text)\n",
    "print(\"\\n======================================================================\\n\")\n",
    "\n",
    "stop_words = StopWords_Removal(dox_2)\n",
    "print(stop_words)\n",
    "print(\"\\n======================================================================\\n\")\n",
    "\n",
    "vocab_func = vocab(dox_2)\n",
    "print(vocab_func)\n",
    "\n",
    "print(\"\\n======================================================================\\n\")\n",
    "pos = POS_tag(dox_1)\n",
    "print(pos)\n",
    "\n",
    "print(\"\\n======================================================================\\n\")\n",
    "lemma = lemmatiz(dox_2)\n",
    "print(lemma)\n",
    "\n",
    "print(\"\\n======================================================================\\n\")\n",
    "stem = Stemming(dox_2)\n",
    "print(stem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
