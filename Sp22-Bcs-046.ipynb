{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Muhammad Ibrahim\n",
    "\n",
    "Sp22-Bcs-046"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tagged Sentence:\n",
      "[('European', 'JJ'), ('authorities', 'NNS'), ('fined', 'VBD'), ('Google', 'NNP'), ('a', 'DT'), ('record', 'NN'), ('$', '$'), ('5.1', 'CD'), ('billion', 'CD'), ('on', 'IN'), ('Wednesday', 'NNP'), ('for', 'IN'), ('market', 'NN'), ('violations', 'NNS'), ('and', 'CC'), ('ordered', 'VBN'), ('changes', 'NNS'), ('.', '.'), ('Life', 'NN'), ('is', 'VBZ'), ('the', 'DT'), ('canvas', 'NN'), (';', ':'), ('fill', 'VB'), ('it', 'PRP'), ('with', 'IN'), ('strokes', 'NNS'), ('of', 'IN'), ('kindness', 'NN'), ('and', 'CC'), ('hues', 'NNS'), ('of', 'IN'), ('resilience', 'NN'), ('.', '.')]\n",
      "\n",
      "Named Entities:\n",
      "(S\n",
      "  (GPE European/JJ)\n",
      "  authorities/NNS\n",
      "  fined/VBD\n",
      "  (PERSON Google/NNP)\n",
      "  a/DT\n",
      "  record/NN\n",
      "  $/$\n",
      "  5.1/CD\n",
      "  billion/CD\n",
      "  on/IN\n",
      "  Wednesday/NNP\n",
      "  for/IN\n",
      "  market/NN\n",
      "  violations/NNS\n",
      "  and/CC\n",
      "  ordered/VBN\n",
      "  changes/NNS\n",
      "  ./.\n",
      "  Life/NN\n",
      "  is/VBZ\n",
      "  the/DT\n",
      "  canvas/NN\n",
      "  ;/:\n",
      "  fill/VB\n",
      "  it/PRP\n",
      "  with/IN\n",
      "  strokes/NNS\n",
      "  of/IN\n",
      "  kindness/NN\n",
      "  and/CC\n",
      "  hues/NNS\n",
      "  of/IN\n",
      "  resilience/NN\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "input_sentence = \"European authorities fined Google a record $5.1 billion on Wednesday for market violations and ordered changes. \"\n",
    "\n",
    "tagged_sentence = pos_tag(word_tokenize(input_sentence))\n",
    "print(\"Tagged Sentence:\")\n",
    "print(tagged_sentence)\n",
    "\n",
    "named_entity_tree = ne_chunk(tagged_sentence)\n",
    "print(\"\\nNamed Entities:\")\n",
    "print(named_entity_tree)\n",
    "\n",
    "named_entity_tree.draw()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
